{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNFkEjH+1kMPBm3U5Ib3n1L"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":15,"metadata":{"id":"2JsxHmEHVGFL","executionInfo":{"status":"error","timestamp":1756244026192,"user_tz":180,"elapsed":32,"user":{"displayName":"fernando nicolas","userId":"00624475207451528011"}},"colab":{"base_uri":"https://localhost:8080/","height":384},"outputId":"fbc78d62-b374-417d-ed2c-4993ef480e10"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'neuralnetwork'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2944550505.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# from torch.utils.tensorboard import SummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# import torch.nn # alterei essa linha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mneuralnetwork\u001b[0m  \u001b[0;31m# Não funcionou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# from torch.nn import UNet, SequentialCNN, UNetWithFeedforwardCNN     # Também não funcionou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'neuralnetwork'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["# Exercise 12 - Learning Strain Distributions\n","\n","import torch\n","from torch.utils.data import DataLoader\n","import torchsummary                 # Alterei essa linha\n","import numpy as np\n","import time\n","import matplotlib.pyplot as plt\n","# from torch.utils.tensorboard import SummaryWriter\n","# import torch.nn # alterei essa linha\n","import NeuralNetwork  # Não funcionou\n","# from torch.nn import UNet, SequentialCNN, UNetWithFeedforwardCNN     # Também não funcionou\n","import datetime\n","import copy\n","import torchvision\n","# from mymodule import UNetWithSubsequentFeedforwardCNN # Foi uma sugestão da internet para tentar corrigir o erro, ele não estava aceitando o comando original (Para as opções 0 ou 1 eu consegui arrumar, mas essa em questão não)\n","\n","# User settings\n","\n","# tensorBoard options\n","\n","writeGraph = False\n","# É o comando para impedir que os dados sejam salvos em disco.\n","writeHistogram = False\n","# é o comando para não salvar histogramas (É um grafico de barras que representa a distribuição de um conjunto de dados)\n","writeLearningHistory = False\n","# É o comando para não salvar o histórico ou registro de aprendizagem durante o treinamento do modelo\n","writePredictions = False\n","# É o comando para não salvar o histórico de predições\n","\n","# driver setup\n","\n","seed = 2\n","torch.manual_seed(seed)\n","# torch.maual_seed é o comando onde nós damos o valor para seed, e essa aleatória será salva para as próximas execuções.\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# É uma forma de solicitar fazer por GPU, caso tenha alguma disponivel\n","writer = SummaryWriter(log_dir=\"./logs/fit\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","# SummaryWriter é usado para registrar eventos e dados de treinamentos para a visualização do TensorBoard.\n","# log_dir define o diretório onde serão salvos esses arquivos log, strftime(\"%Y%m%d-%H%M%S\") é o comando para salvar o ano, mÊs, dia, hora, minuto e segundo\n","\n","#neural network architecture selection\n","selectNN = 0  # 0 for UNet, 1 for sequential CNN, 2 for UNet with subsequent feedforward CNN (Não funcionou)\n","\n","# model parameters\n","\n","kernelSize = 3\n","\n","if selectNN == 0:\n","    channels = [1, 32, 64]\n","# channels = [] faz referencia ao numero de filtros utilizados, serão 1 filtro na primeira camada, 32 na seguinda e 62 na terceira.\n","    channelsOut = 3\n","# channelsout faz referência a quantidade de saidas, no casso serão 3 classes.\n","    numberOfConvolutionsPerBlock = 1\n","    model = torch.nn.UNet(channels, channelsOut, numberOfConvolutionsPerBlock, kernelSize)\n","elif selectNN == 1:\n","    channels = [1, 32, 64, 32]\n","    channelsOut = 3\n","    model = torch.nn.FeedforwardCNN(channels, channelsOut, kernelSize)\n","# elif selectNN == 2:  # Não consegui fazer rodar\n","#     channelsUNet = [1, 32, 64]\n","#     numberOfConvolutionsPerBlockUNet = 1\n","#     channelsFeedforwardCNN = [64, 32, 16]\n","#     channelsOut = 3\n","#     model = UNetWithSubsequentFeedforwardCNN(channelsUNet, numberOfConvolutionsPerBlockUNet,\n","#                                                            channelsFeedforwardCNN, channelsOut, kernelSize)\n","model.to(device)\n","\n","summary(model, (1, 1, 32, 32))\n","# summary (model, ()) é uma forma de verificar no modelo, informando a dimensão de entrada quantos parametros serão utilizados.\n","if writeGraph == True:\n","    writer.add_graph(model, torch.randn((1, 1, 32, 32), device=device))\n","\n","# hyperparameters\n","batchSize = 128\n","alpha = -0.2\n","beta = 0.2\n","weightDecay = 0\n","lr = 2e-3\n","epochs = 1000\n","earlyStopping = True\n","# É o comando para parar o treinamento automaticamente, caso a metrica seja a mesma ou comece a piorar durante o treinamento.\n","\n","\n"]}]}